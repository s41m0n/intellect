{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trials of pruning techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s41m0n/Desktop/intellect/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import from_numpy\n",
    "import sys\n",
    "import numpy as np\n",
    "if \"../\" not in sys.path:\n",
    "    sys.path.insert(0, '../')\n",
    "    sys.path.insert(0, '../scripts')\n",
    "import scripts.utils.pruning as pruning\n",
    "from scripts.utils.common import set_seed\n",
    "from scripts.utils.model import get_prunable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Example(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Example, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        self.fc2 = nn.Linear(5, 5)\n",
    "        self.fc3 = nn.Linear(5, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "X = from_numpy(np.random.rand(2,10)).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Globally Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 15:36:33,411 - pruning - INFO - Globally Pruning using amount=0.5 method=LnStructured and n.len(layers)=3 layers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 1., 1., 1., 0., 1., 1., 0., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 0.]])\n",
      "tensor([[1., 0., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1.]])\n",
      "tensor([[0., 0., 0., 0., 0.]])\n",
      "tensor([[0.0219],\n",
      "        [0.0100]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.1639],\n",
      "        [0.1639]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "\n",
    "model = Example()\n",
    "prev = model(X)\n",
    "pruning.globally_structured_connections_l1(model, get_prunable(model), 0.5)\n",
    "post = model(X)\n",
    "\n",
    "print(model.fc1.weight_mask)\n",
    "print(model.fc2.weight_mask)\n",
    "print(model.fc3.weight_mask)\n",
    "print(prev)\n",
    "print(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 12:28:13,107 - pruning - INFO - Globally Pruning using amount=0.5 method=LnStructured and n.len(layers)=3 layers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0.]])\n",
      "tensor([[0.0219],\n",
      "        [0.0100]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.1639],\n",
      "        [0.1639]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "model = Example()\n",
    "prev = model(X)\n",
    "pruning.globally_structured_connections_random(model, get_prunable(model), 0.5)\n",
    "post = model(X)\n",
    "print(model.fc1.weight_mask)\n",
    "print(model.fc2.weight_mask)\n",
    "print(model.fc3.weight_mask)\n",
    "print(prev)\n",
    "print(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 12:12:47,830 - pruning - INFO - Globally Pruning using amount=0.5 method=LnStructured and n.len(layers)=3 layers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "model = Example()\n",
    "pruning.globally_structured_neurons_l1(model, get_prunable(model), 0.5)\n",
    "print(model.fc1.weight_mask)\n",
    "print(model.fc2.weight_mask)\n",
    "print(model.fc3.weight_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 12:15:26,152 - pruning - INFO - Globally Pruning using amount=0.5 method=RandomStructured and n.len(layers)=3 layers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "model = Example()\n",
    "pruning.globally_structured_neurons_random(model, get_prunable(model), 0.5)\n",
    "print(model.fc1.weight_mask)\n",
    "print(model.fc2.weight_mask)\n",
    "print(model.fc3.weight_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 12:15:43,562 - pruning - INFO - Globally Pruning using amount=0.5 method=L1Unstructured and n.len(layers)=3 layers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 1., 1., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 1., 0., 0., 0., 1., 1., 0.],\n",
      "        [0., 1., 0., 1., 0., 0., 1., 1., 1., 0.],\n",
      "        [0., 1., 1., 0., 1., 1., 1., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 1., 0., 1., 1., 0., 0.]])\n",
      "tensor([[1., 0., 1., 1., 1.],\n",
      "        [1., 1., 1., 0., 1.],\n",
      "        [0., 0., 0., 1., 1.],\n",
      "        [1., 0., 0., 1., 1.],\n",
      "        [1., 0., 1., 0., 1.]])\n",
      "tensor([[0., 0., 1., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "model = Example()\n",
    "pruning.globally_unstructured_connections_l1(model, get_prunable(model), 0.5)\n",
    "print(model.fc1.weight_mask)\n",
    "print(model.fc2.weight_mask)\n",
    "print(model.fc3.weight_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 12:15:55,758 - pruning - INFO - Globally Pruning using amount=0.5 method=RandomUnstructured and n.len(layers)=3 layers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 1.],\n",
      "        [0., 0., 1., 1., 1., 1., 1., 0., 0., 1.],\n",
      "        [0., 1., 1., 1., 1., 1., 1., 1., 1., 0.]])\n",
      "tensor([[0., 0., 0., 1., 1.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 0.],\n",
      "        [1., 1., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 1.]])\n",
      "tensor([[1., 0., 1., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "model = Example()\n",
    "pruning.globally_unstructured_connections_random(model, get_prunable(model), 0.5)\n",
    "print(model.fc1.weight_mask)\n",
    "print(model.fc2.weight_mask)\n",
    "print(model.fc3.weight_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 12:21:44,490 - pruning - INFO - Globally Pruning Neurons looking for activation, length of subset provided len(subset_features)=0 amount=0.5 and n.len(layers)=3 layers n=1\n",
      "2023-09-15 12:21:44,490 - pruning - INFO - Getting neurons' activations\n",
      "2023-09-15 12:21:44,493 - pruning - INFO - Globally Pruning using amount=0.5 method=LnStructured and n.len(layers)=3 layers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5])\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 5])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0.]])\n",
      "tensor([[0.0640],\n",
      "        [0.0640]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.1639],\n",
      "        [0.1639]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "model = Example()\n",
    "prev = model(X)\n",
    "pruning.globally_structured_neurons_activation_l1(model, get_prunable(model), 0.5, X)\n",
    "post = model(X)\n",
    "print(model.fc1.weight_mask)\n",
    "print(model.fc2.weight_mask)\n",
    "print(model.fc3.weight_mask)\n",
    "print(prev)\n",
    "print(post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locally Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 12:17:00,371 - pruning - INFO - Locally Pruning Connections structured=True using amount=[0.5, 0.5, 0.5] n=1 dim=1 and n.len(layers)=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 1., 1., 0., 0., 1., 1., 0., 0.],\n",
      "        [0., 1., 1., 1., 0., 0., 1., 1., 0., 0.],\n",
      "        [0., 1., 1., 1., 0., 0., 1., 1., 0., 0.],\n",
      "        [0., 1., 1., 1., 0., 0., 1., 1., 0., 0.],\n",
      "        [0., 1., 1., 1., 0., 0., 1., 1., 0., 0.]])\n",
      "tensor([[1., 0., 1., 0., 1.],\n",
      "        [1., 0., 1., 0., 1.],\n",
      "        [1., 0., 1., 0., 1.],\n",
      "        [1., 0., 1., 0., 1.],\n",
      "        [1., 0., 1., 0., 1.]])\n",
      "tensor([[0., 0., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "model = Example()\n",
    "layers = get_prunable(model)\n",
    "pruning.locally_structured_connections_l1(model, layers, [0.5]*len(layers))\n",
    "print(model.fc1.weight_mask)\n",
    "print(model.fc2.weight_mask)\n",
    "print(model.fc3.weight_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 12:17:36,416 - pruning - INFO - Locally Pruning Connections structured=True using amount=[0.5, 0.5, 0.5] n=0 dim=1 and n.len(layers)=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 0., 0., 1., 0., 0., 0., 1.],\n",
      "        [1., 1., 1., 0., 0., 1., 0., 0., 0., 1.],\n",
      "        [1., 1., 1., 0., 0., 1., 0., 0., 0., 1.],\n",
      "        [1., 1., 1., 0., 0., 1., 0., 0., 0., 1.],\n",
      "        [1., 1., 1., 0., 0., 1., 0., 0., 0., 1.]])\n",
      "tensor([[1., 0., 1., 0., 1.],\n",
      "        [1., 0., 1., 0., 1.],\n",
      "        [1., 0., 1., 0., 1.],\n",
      "        [1., 0., 1., 0., 1.],\n",
      "        [1., 0., 1., 0., 1.]])\n",
      "tensor([[0., 0., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "model = Example()\n",
    "layers = get_prunable(model)\n",
    "pruning.locally_structured_connections_random(model, layers, [0.5]*len(layers))\n",
    "print(model.fc1.weight_mask)\n",
    "print(model.fc2.weight_mask)\n",
    "print(model.fc3.weight_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 12:17:54,746 - pruning - INFO - Locally Pruning Neurons structured=True using amount=[0.5, 0.5, 0.5] n=1 dim=0 and n.len(layers)=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n",
      "tensor([[1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "model = Example()\n",
    "layers = get_prunable(model)\n",
    "pruning.locally_structured_neurons_l1(model, layers, [0.5]*len(layers))\n",
    "print(model.fc1.weight_mask)\n",
    "print(model.fc2.weight_mask)\n",
    "print(model.fc3.weight_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 12:18:00,891 - pruning - INFO - Locally Pruning Neurons structured=True using amount=[0.5, 0.5, 0.5] n=0 dim=0 and n.len(layers)=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1.]])\n",
      "tensor([[1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "model = Example()\n",
    "layers = get_prunable(model)\n",
    "pruning.locally_structured_neurons_random(model, layers, [0.5]*len(layers))\n",
    "print(model.fc1.weight_mask)\n",
    "print(model.fc2.weight_mask)\n",
    "print(model.fc3.weight_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
